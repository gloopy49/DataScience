{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import json\n",
    "#import joblib\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from itertools import compress\n",
    "#import xgboost as xgb\n",
    "#import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import RFECV\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from xgboost import XGBClassifier\n",
    "#from xgboost import plot_importance\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "#import pydotplus\n",
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "#import shap\n",
    "import math\n",
    "#shap.initjs()\n",
    "pd.set_option('display.max_rows',100)\n",
    "pd.set_option('display.max_columns',100)\n",
    "gc.enable()\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('LoanStats3a.csv',skip_blank_lines = True,skiprows = 1,skipfooter = 2,engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null percentage for all columns\n",
    "null_df=data.isnull().mean().reset_index()\n",
    "null_df.columns=['column_name','null_percent']\n",
    "null_df.sort_values(by='null_percent',ascending=False, inplace=True)\n",
    "\n",
    "null_df.plot(x='column_name',y='null_percent', style='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Engineerig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with NA percentage>0.99\n",
    "null_cols=null_df[null_df['null_percent']>0.99].column_name.tolist()\n",
    "null_cols\n",
    "df0=data.drop(null_cols,axis=1)\n",
    "print(\"Dropping null columns...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows with NA in target variable\n",
    "df0.dropna(subset=['loan_status'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check loan_status counts for each category\n",
    "df0['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.loan_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive response variable \"default\"\n",
    "df0['default'] = df0.loan_status.apply(lambda x: 1 if x == \"Charged Off\" or x == \"Does not meet the credit policy. Status:Charged Off\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data types\n",
    "# create a new feature 'credit_len'\n",
    "# drop columns ['issue_d','earliest_cr_line']\n",
    "df0['credit_len'] = (pd.to_datetime(df0['issue_d']) - pd.to_datetime(df0['earliest_cr_line'])).dt.days\n",
    "df0.drop(['issue_d','earliest_cr_line'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA in credit_len with 0\n",
    "df0['credit_len'].fillna(0, inplace=True)\n",
    "df0['credit_len'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that happen after default\n",
    "drop_attr=['title','out_prncp','out_prncp_inv',\n",
    "           'policy_code', 'delinq_amnt', \n",
    "           'recoveries','total_rec_late_fee',\n",
    "           'last_pymnt_amnt','application_type','desc',\n",
    "            'emp_title','loan_status',\n",
    "             'zip_code','addr_state','total_rec_prncp',\n",
    "            'total_rec_int','total_pymnt',\n",
    "            'pymnt_plan','initial_list_status', 'last_pymnt_d',\n",
    "            'last_credit_pull_d','hardship_flag','tax_liens',\n",
    "            'total_pymnt_inv','collection_recovery_fee','debt_settlement_flag','next_pymnt_d','pymnt_plan']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop variables that are not available at the time of application\n",
    "df0.drop(drop_attr,inplace=True, axis=1)\n",
    "df0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the only one factor columns\n",
    "columns=df0.columns[df0.nunique(dropna = False)==1]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop one factor columns\n",
    "df0.drop(columns=df0.columns[df0.nunique(dropna = False)==1], inplace=True)\n",
    "df0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform 'int_rate' and 'revol_util' to numerical variable\n",
    "df0['int_rate'] = df0.int_rate.str.extract('(\\d+)').astype('float')\n",
    "df0['revol_util'] = df0.revol_util.str.extract('(\\d+)').astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform emp_length to numerical variable\n",
    "mapping_dict = {\n",
    "\"emp_length\": {\n",
    "\"10+ years\": 10,\n",
    "\"9 years\": 9,\n",
    "\"8 years\": 8,\n",
    "\"7 years\": 7,\n",
    "\"6 years\": 6,\n",
    "\"5 years\": 5,\n",
    "\"4 years\": 4,\n",
    "\"3 years\": 3,\n",
    "\"2 years\": 2,\n",
    "\"1 year\": 1,\n",
    "\"< 1 year\": 0,\n",
    "\"n/a\": 0\n",
    "},\n",
    "\"grade\":{\n",
    "\"A\": 1,\n",
    "\"B\": 2,\n",
    "\"C\": 3,\n",
    "\"D\": 4,\n",
    "\"E\": 5,\n",
    "\"F\": 6,\n",
    "\"G\": 7\n",
    "}\n",
    "}\n",
    "df0 = df0.replace(mapping_dict)\n",
    "df0[['emp_length','grade']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical variables\n",
    "attr_cat=['term', 'home_ownership','verification_status','purpose']\n",
    "attr_o = [col for col in df0.select_dtypes(include = 'object').columns.tolist() if col not in ['grade','sub_grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy categorical variables\n",
    "df1 = pd.get_dummies(df0,prefix_sep = '_', columns = attr_o, dummy_na = True, sparse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['pub_rec_bankruptcies'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_mis=['mths_since_last_delinq','revol_util','collections_12_mths_ex_med',\n",
    "          'chargeoff_within_12_mths','pub_rec_bankruptcies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1[np.isfinite(df1['delinq_2yrs'])]\n",
    "df3=df2[np.isfinite(df2['credit_len'])]\n",
    "df3.isnull().sum()[df3.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns with columnname_nan\n",
    "df4=df3[attr_mis].isnull().astype(int).add_suffix('_nan')\n",
    "df5=pd.concat([df3,df4],axis=1)\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill na with 0\n",
    "#df5.fillna(df5.median(skipna=True),inplace=True)\n",
    "df5.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features\n",
    "attr = [col for col in df5.columns if col not in ['default','sub_grade','total_pymnt','total_pymnt_inv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test datasets\n",
    "train_x,test_x,train_y,test_y=train_test_split(df5[attr],df5['default'],test_size=0.3,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Model\n",
    "test=pd.concat([train_x,train_y],axis=1)\n",
    "test[test.columns].corr()['default']\n",
    "\n",
    "selector=RFECV(estimator=LogisticRegression(),step=1,cv=5,scoring='roc_auc')\n",
    "selector.fit(train_x,train_y)\n",
    "#plt.figure()\n",
    "#plt.plot(range(1,len(selector.grid_scores_)+1),selector.grid_scores_)\n",
    "#plt.show()\n",
    "selector.support_\n",
    "selector.ranking_\n",
    "selector.n_features_\n",
    "features=train_x.columns[selector.support_]\n",
    "train_x_1=train_x[features]\n",
    "test_x_1=test_x[features]\n",
    "\n",
    "cor=train_x_1.corr()\n",
    "mask=np.zeros_like(cor,dtype=np.bool)\n",
    "sns.heatmap(cor,mask=mask,center=0,square=True,linewidths=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use lasso to select features\n",
    "param_grid = [\n",
    "    {\n",
    "     'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['liblinear']},\n",
    "]\n",
    "clf = GridSearchCV(estimator=LogisticRegression(), param_grid = param_grid, scoring='roc_auc',cv = 5, verbose=True, n_jobs=-1)\n",
    "clf.fit(train_x_1,train_y)\n",
    "print(clf.best_params_)\n",
    "\n",
    "lr=LogisticRegression(C=1.62,penalty='l1', solver='liblinear')\n",
    "lr.fit(train_x_1,train_y)\n",
    "\n",
    "feature_df=pd.DataFrame({'feature':train_x_1.columns.get_values(),'coef':lr.coef_[0]})\n",
    "feature_l=train_x_1.columns[lr.coef_[0]!=0]\n",
    "pred_lr_train=lr.predict_proba(train_x_1)[:,1]\n",
    "roc_auc_score(train_y,pred_lr_train)\n",
    "#0.7007666596172346\n",
    "pred_lr_test=lr.predict_proba(test_x_1)[:,1]\n",
    "roc_auc_score(test_y,pred_lr_test)\n",
    "#0.6969112243485446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(train_y,pred_lr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(test_y,pred_lr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['issue_d'] = pd.to_datetime(df['issue_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year']=df['issue_d'].dt.year.astype(int,errors='ignore')\n",
    "df['default'] = df.loan_status.apply(lambda x: 1 if x == \"Charged Off\" or x == \"Does not meet the credit policy. Status:Charged Off\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The year of 2011 was the year with the highest amount of loans were issued \n",
    "# Loans increase gradually by year from 2007 to 2011.\n",
    "plt.figure(figsize=(12,8))\n",
    "#sns.barplot('year', 'loan_amnt', data=df, palette='tab10')\n",
    "df.groupby('year')['loan_amnt'].sum().plot(kind='bar')\n",
    "plt.title('Issuance of Loans', fontsize=20)\n",
    "plt.xlabel('Year', fontsize=20)\n",
    "plt.ylabel('Total loan amount issued', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "\n",
    "colors = [\"#3791D7\", \"#D72626\"]\n",
    "labels =\"Good Loans\", \"Bad Loans\"\n",
    "\n",
    "plt.suptitle('Information on Loan Conditions', fontsize=20)\n",
    "\n",
    "df0[\"default\"].value_counts().plot.pie(explode=[0,0.25], autopct='%1.2f%%', ax=ax[0], shadow=True, colors=colors, \n",
    "                                             labels=labels, fontsize=12, startangle=70)\n",
    "\n",
    "\n",
    "# ax[0].set_title('State of Loan', fontsize=16)\n",
    "ax[0].set_ylabel('% of Condition of Loans', fontsize=14)\n",
    "\n",
    "# sns.countplot('loan_condition', data=df, ax=ax[1], palette=colors)\n",
    "# ax[1].set_title('Condition of Loans', fontsize=20)\n",
    "# ax[1].set_xticklabels(['Good', 'Bad'], rotation='horizontal')\n",
    "palette = [\"#3791D7\", \"#E01E1B\"]\n",
    "\n",
    "sns.barplot(x=\"year\", y=\"loan_amnt\", hue=\"default\", data=df, palette=palette, estimator=lambda x: len(x) / len(df) * 100)\n",
    "ax[1].set(ylabel=\"(%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['int_rate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average interest is 11.59% Anything above this will be considered of high risk let's see if this is true.\n",
    "df0['interest_level'] = np.nan\n",
    "lst = [df0]\n",
    "\n",
    "for col in lst:\n",
    "    col.loc[col['int_rate'] <= 13.23, 'interest_level'] = 'Low'\n",
    "    col.loc[col['int_rate'] > 13.23, 'interest_level'] = 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "palette = ['#009393', '#930000']\n",
    "plt.subplot(221)\n",
    "ax = sns.countplot(x='interest_level', data=df0, \n",
    "                  palette=palette, hue='default')\n",
    "\n",
    "ax.set_title('The impact of interest rate \\n on the condition of the loan', fontsize=14)\n",
    "ax.set_xlabel('Level of Interest Payments', fontsize=12)\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.subplot(222)\n",
    "#ax1 = sns.countplot(x='interest_level', data=df0, \n",
    "                   #palette=palette, hue='term')\n",
    "ax1 = sns.countplot(x='term', data=df0, \n",
    "                   palette=palette, hue='default')\n",
    "ax1.set_title('The impact of maturity date \\n on the condition of the loan', fontsize=14)\n",
    "ax1.set_xlabel('Term', fontsize=12)\n",
    "ax1.set_ylabel('Count')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total \n",
    "total_funded_amount=df['funded_amnt_inv'].sum()\n",
    "total_payment_amount=df['total_pymnt_inv'].sum()\n",
    "\n",
    "total_return_rate=(total_payment_amount-total_funded_amount)/total_funded_amount\n",
    "total_return_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=df.groupby('year')['funded_amnt_inv','total_pymnt_inv'].sum().reset_index().sort_values(by='year')\n",
    "d1['return_rate']= (d1['total_pymnt_inv']-d1['funded_amnt_inv'])/d1['funded_amnt_inv']\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return rate\n",
    "\n",
    "plt.clf()\n",
    "d1.groupby('year')['return_rate'].sum().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
